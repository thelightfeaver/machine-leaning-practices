{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library and download datasets\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import tarfile\n",
    "import urllib.request\n",
    "\n",
    "def load_housing_data():\n",
    "    tarball_path = Path(\"datasets/housing.tgz\")\n",
    "\n",
    "    if not tarball_path.is_file():\n",
    "        Path(\"datasets\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        url = \"https://github.com/ageron/data/raw/main/housing.tgz\"\n",
    "        urllib.request.urlretrieve(url, tarball_path)\n",
    "\n",
    "        with tarfile.open(tarball_path) as housing_tarball:\n",
    "            housing_tarball.extractall(path='datasets')\n",
    "\n",
    "    return pd.read_csv(Path(\"datasets/housing/housing.csv\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df_housing = load_housing_data()\n",
    "df_housing.info()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_housing['ocean_proximity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# util\n",
    "import numpy as np\n",
    "from zlib import crc32\n",
    "\n",
    "\n",
    "# function for splitting data into train and test sets\n",
    "def shuffle_and_split_data(data, test_ratio):\n",
    "    shuffled_indices = np.random.permutation(len(data))\n",
    "    test_set_size = int(len(data) * test_ratio)\n",
    "    test_indices = shuffled_indices[:test_set_size]\n",
    "    train_indices = shuffled_indices[test_set_size:]\n",
    "    return data.iloc[train_indices], data.iloc[test_indices]\n",
    "\n",
    "# another ways to split data using id hash\n",
    "def is_id_in_test_set(id, test_ratio):\n",
    "    return crc32(np.int64(id)) & 0xffffffff < test_ratio * 2**32\n",
    "\n",
    "def split_data_with_id_hash(data, test_ratio, id_column):\n",
    "    ids = data[id_column]\n",
    "    in_test_set = ids.apply(lambda id_: is_id_in_test_set(id_, test_ratio))\n",
    "    return data.loc[~in_test_set], data.loc[in_test_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test sets using shuffle\n",
    "train_set, test_set = shuffle_and_split_data(df_housing, 0.2)\n",
    "display(\"Train Data Shuffle: \"+str(len(train_set)))\n",
    "display(\"Test Data Shuffle: \"+str(len(test_set))) \n",
    "\n",
    "# split data into train and test sets using id hash\n",
    "df_housing_with_id = df_housing.reset_index()\n",
    "train_set, test_set = split_data_with_id_hash(df_housing_with_id, 0.2, \"index\")\n",
    "display(\"Train Data Hash: \"+str(len(train_set)))\n",
    "display(\"Test Data Hash: \"+str(len(test_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating income category attribute\n",
    "df_housing[\"income_cat\"] = pd.cut(df_housing[\"median_income\"],\n",
    "                                    bins=[0., 1.5, 3.0, 4.5, 6., np.inf],\n",
    "                                    labels=[1, 2, 3, 4, 5])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# df_housing[\"income_cat\"].value_counts().sort_index().plot.bar(rot=0 ,grid=True)\n",
    "df_housing[\"income_cat\"].hist()\n",
    "plt.xlabel(\"Income Category\")\n",
    "plt.ylabel(\"Number of districts\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets using stratified sampling\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "strat_splits = []\n",
    "for train_index, test_index in split.split(df_housing, df_housing[\"income_cat\"]):\n",
    "    strat_train_set_n = df_housing.loc[train_index]\n",
    "    strat_test_set_n = df_housing.loc[test_index]\n",
    "    strat_splits.append((strat_train_set_n, strat_test_set_n))\n",
    "\n",
    "strat_train_set, strat_test_set = strat_splits[0]\n",
    "display(\"Train Data Stratified: \"+str(len(strat_train_set)))\n",
    "display(\"Test Data Stratified: \"+str(len(strat_test_set)))\n",
    "\n",
    "strat_train_set, strat_test_set = train_test_split(df_housing, \n",
    "                                                   test_size=0.2, \n",
    "                                                   random_state=42, \n",
    "                                                   stratify=df_housing[\"income_cat\"])\n",
    "display(\"Train Data Split: \"+str(len(strat_train_set)))\n",
    "display(\"Test Data Split: \"+str(len(strat_test_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove income_cat attribute\n",
    "for set_ in (strat_train_set, strat_test_set):\n",
    "    set_.drop(\"income_cat\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show in scater longitude and latitude\n",
    "\n",
    "housing = strat_train_set.copy()\n",
    "housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.4, grid=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\",\n",
    "             s=housing[\"population\"]/100, label=\"Population\",\n",
    "                c=\"median_house_value\", cmap='jet',colorbar=True,\n",
    "                legend=True, sharex=False, figsize=(11,7))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking for correlations\n",
    "h = housing.copy() \n",
    "h.drop(\"ocean_proximity\",axis=1, inplace=True)\n",
    "corr_matrix = housing.corr()\n",
    "corr_matrix[\"median_house_value\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ways to check correlation\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "attributes = [\"median_house_value\", \"median_income\", \"total_rooms\",\n",
    "                \"housing_median_age\"]\n",
    "\n",
    "scatter_matrix(housing[attributes], figsize=(12,8))\n",
    "\n",
    "housing.plot(kind=\"scatter\",\n",
    "             x=\"median_income\",\n",
    "             y=\"median_house_value\",\n",
    "             alpha=0.1,\n",
    "             grid=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation between attributes\n",
    "housing[\"rooms_per_household\"] = housing[\"total_rooms\"]/housing[\"households\"]\n",
    "housing[\"bedrooms_per_room\"] = housing[\"total_bedrooms\"]/housing[\"total_rooms\"]\n",
    "housing[\"people_per_household\"] = housing[\"population\"]/housing[\"households\"]\n",
    "\n",
    "corr_matrix = housing.corr()\n",
    "corr_matrix[\"median_house_value\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparation data for machine learning algorithms\n",
    "housing = strat_train_set.drop(\"median_house_value\", axis=1)\n",
    "housing_labels = strat_train_set[\"median_house_value\"].copy()\n",
    "\n",
    "# data cleaning\n",
    "\n",
    "housing.dropna(subset=[\"total_bedrooms\"]) # option 1\n",
    "housing.drop(\"total_bedrooms\", axis=1) # option 2\n",
    "median = housing[\"total_bedrooms\"].median() # option 3\n",
    "housing[\"total_bedrooms\"].fillna(median, inplace=True)\n",
    "\n",
    "# using SimpleImputer is better way to fill missing values\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "housing_num = housing.select_dtypes(include=[np.number])\n",
    "imputer.fit(housing_num)\n",
    "display(imputer.statistics_)\n",
    "display(housing_num.median().values)\n",
    "\n",
    "\n",
    "X = imputer.transform(housing_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return the result to a pandas DataFrame.\n",
    "housing_tr = pd.DataFrame(X, columns=housing_num.columns,\n",
    "                          index=housing_num.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tranform categorical attributes to numerical\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "housing_cat_encoded = ordinal_encoder.fit_transform(housing[[\"ocean_proximity\"]])\n",
    "\n",
    "display(housing_cat_encoded[:10])\n",
    "# show categories\n",
    "display(ordinal_encoder.categories_)\n",
    "\n",
    "# one hot encoding\n",
    "cat_encoder = OneHotEncoder()\n",
    "housing_cat_1hot = cat_encoder.fit_transform(housing[[\"ocean_proximity\"]])\n",
    "display(housing_cat_1hot.toarray())\n",
    "\n",
    "# custom transformer\n",
    "df_test = pd.DataFrame({\"ocean_proximity\": [\"<1H OCEAN\", \"INLAND\", \"NEAR OCEAN\", \"NEAR BAY\", \"ISLAND\"]})\n",
    "pd.get_dummies(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
